{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt=\"\"\"\n",
    "You are an agent in a \"color-mixing environment\". The environment consists \n",
    "    of several beakers, each containing a paint of a certain color and amount. \n",
    "    Your objective is to mix colors in beakers such that one beaker matches \n",
    "    a target beaker as close as possible (in both color and amount).\n",
    "\n",
    "    At each timestep, you will be given a textual representation of environment\n",
    "    which tells you the RGB value and amount of paints in each beaker as well\n",
    "    as the target beaker you are trying to achieve.\n",
    "    \n",
    "    Given this description of the envrionment, your task is to generate an \n",
    "    action in a specific JSON format. Each action is a JSON object that \n",
    "    represents a move in the envivronment. The action should consist of the \n",
    "    following elements:\n",
    "\n",
    "    - \"from_beaker\": An integer representing the index of the beaker from which the paint is poured.\n",
    "    - \"to_beaker\": An integer representing the index of the beaker to which the paint is poured.\n",
    "    - \"transfer_amount\": An integer (0 to 100) indicating how much paint (in ml) is transferred from the 'from_beaker' to the 'to_beaker'.\n",
    "    - \"is_done\": A boolean value (true or false). Set to true if this is the final action and you want to compare the current state with the target. Set to false otherwise.\n",
    "    - \"compare_beaker\": An integer representing the index of the beaker to compare with the target when 'is_done' is true. This field is only relevant if 'is_done' is true.\n",
    "\n",
    "    Your actions in the environment should work towards producing a beaker\n",
    "    which is as close as possible to the target beaker (in both color and \n",
    "    amount) in as few steps as possible.\n",
    "\n",
    "    Note that the environment uses a subtractive color mixing model. You should \n",
    "    leverage this fact to predict the result of mixing two colors for the \n",
    "    purposes of planning. For reference, this is the function used mix colors:\n",
    "\n",
    "    class SubtractiveModel:\n",
    "    @staticmethod\n",
    "    def _rgb_to_cmy(rgb: Tuple[int, int, int]) -> Tuple[int, int, int]:\n",
    "        return tuple(255 - value for value in rgb)\n",
    "\n",
    "    @staticmethod\n",
    "    def _cmy_to_rgb(cmy: Tuple[int, int, int]) -> Tuple[int, int, int]:\n",
    "        return tuple(255 - value for value in cmy)\n",
    "\n",
    "    @staticmethod\n",
    "    def mix_colors(paint1: 'Paint', paint2: 'Paint') -> Tuple[int, int, int]:\n",
    "        cmy1 = SubtractiveModel._rgb_to_cmy(paint1.color)\n",
    "        cmy2 = SubtractiveModel._rgb_to_cmy(paint2.color)\n",
    "        total_amount = paint1.amount + paint2.amount\n",
    "        if paint1.amount == 0:\n",
    "            return paint2.color\n",
    "        if paint2.amount == 0:\n",
    "            return paint1.color\n",
    "\n",
    "        mixed_cmy = tuple(int((cmy1[i] * paint1.amount + cmy2[i] * paint2.amount) / total_amount) for i in range(3))\n",
    "        return SubtractiveModel._cmy_to_rgb(mixed_cmy)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = []\n",
    "messages.append({\"role\": \"system\", \"content\": system_prompt})\n",
    "obs = \"\"\"Given the following beakers: \n",
    "Beaker 0: RGB(252, 251, 0), 107ml\n",
    "Beaker 1: RGB(0, 0, 0), 0ml\n",
    "Beaker 2: RGB(255, 0, 255), 80ml\n",
    "Beaker 3: RGB(200, 108, 52), 97ml\n",
    "Beaker 4: RGB(5, 255, 255), 101ml\n",
    "Target beaker: RGB(44, 220, 226), 63ml\n",
    "Please output your action given this state.\"\"\"\n",
    "messages.append({\"role\": \"user\", \"content\": obs})\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo-1106\",  \n",
    "    response_format={\"type\" : \"json_object\"},\n",
    "    messages=messages\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\\n  \"from_beaker\": 0,\\n  \"to_beaker\": 1,\\n  \"transfer_amount\": 63,\\n  \"is_done\": true,\\n  \"compare_beaker\": 1\\n}'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 1, 63, True, 1)\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "# Parse the JSON string\n",
    "action_json = response.choices[0].message.content\n",
    "action_data = json.loads(action_json)\n",
    "\n",
    "# Extract action components\n",
    "from_beaker = action_data.get(\"from_beaker\", 0)\n",
    "to_beaker = action_data.get(\"to_beaker\", 0)\n",
    "transfer_amount = action_data.get(\"transfer_amount\", 0)\n",
    "is_done = action_data.get(\"is_done\", False)\n",
    "compare_beaker = action_data.get(\"compare_beaker\", 0) if is_done else 0\n",
    "\n",
    "# Ensure the action components are within the bounds of the action space\n",
    "# from_beaker = min(max(from_beaker, 0), action_space.nvec[0] - 1)\n",
    "# to_beaker = min(max(to_beaker, 0), action_space.nvec[1] - 1)\n",
    "# transfer_amount = min(max(transfer_amount, 0), action_space.nvec[2] - 1)\n",
    "# is_done = 1 if is_done else 0\n",
    "# compare_beaker = min(max(compare_beaker, 0), action_space.nvec[4] - 1)\n",
    "\n",
    "# Construct the action tuple\n",
    "action = (from_beaker, to_beaker, transfer_amount, is_done, compare_beaker)\n",
    "print(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlvr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
