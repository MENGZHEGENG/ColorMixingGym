{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_pddl_sections(text, section_name):\n",
    "    lines = text.split('\\n')\n",
    "    start_index = -1\n",
    "    end_index = -1\n",
    "    predicates = []\n",
    "    \n",
    "    # Find the start of the section\n",
    "    for i, line in enumerate(lines):\n",
    "        if line.strip().startswith(f\"(:{section_name}\"):\n",
    "            start_index = i\n",
    "            break\n",
    "    \n",
    "    # If the start was found, look for the end\n",
    "    if start_index != -1:\n",
    "        for i, line in enumerate(lines[start_index+1:], start=start_index+1):\n",
    "            if line.strip() == \")\":\n",
    "                end_index = i\n",
    "                break\n",
    "    \n",
    "    # Extract predicates if both start and end were found\n",
    "    if start_index != -1 and end_index != -1:\n",
    "        predicates = [line.strip().strip('()') for line in lines[start_index+1:end_index] if line.strip() and line.strip() != \"(and\"]\n",
    "    \n",
    "    return predicates\n",
    "\n",
    "def parse_pddl(text):\n",
    "    initial_state = parse_pddl_sections(text, \"init\")\n",
    "    goal_state = parse_pddl_sections(text, \"goal\")\n",
    "    # Further clean goal_state to remove any trailing parentheses in elements\n",
    "    goal_state = [predicate.rstrip(')') for predicate in goal_state]\n",
    "    return initial_state, goal_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step = 2\n",
    "# step = 4\n",
    "step = 6\n",
    "\n",
    "f = open(f\"data/step_{step}.json\")\n",
    "\n",
    "data = json.load(f)\n",
    "\n",
    "for elem in data:\n",
    "    path, gt_actions, _ = elem\n",
    "    filename = os.path.basename(path)\n",
    "    real_path = f\"data/{filename}\"\n",
    "    \n",
    "    with open(real_path, 'r') as file:\n",
    "        file_contents = file.read()\n",
    "    # print(file_contents)\n",
    "    init_state, goal_state = parse_pddl(file_contents)\n",
    "\n",
    "    gt_actions = [action.strip(\"()\") for action in gt_actions.strip().split(\"\\n\")]\n",
    "    # print(gt_actions)\n",
    "\n",
    "    parsed_file = {\n",
    "        \"init_state\": init_state,\n",
    "        \"goal_state\": goal_state,\n",
    "        \"action_seq\": gt_actions\n",
    "    }\n",
    "\n",
    "    new_path = f\"data_parsed/step_{step}/{filename}\"\n",
    "    \n",
    "    with open(new_path, 'w') as json_file:\n",
    "        json.dump(parsed_file, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pick-up 157\n",
      "stack 253\n",
      "unstack 243\n",
      "put-down 147\n"
     ]
    }
   ],
   "source": [
    "from env import BlocksWorld\n",
    "from world_model import BlocksWorldModelInit\n",
    "import random\n",
    "from collections import defaultdict\n",
    "\n",
    "dummy_model = BlocksWorldModelInit()\n",
    "env = BlocksWorld()\n",
    "transitions = defaultdict(list)\n",
    "\n",
    "num_levels = 100\n",
    "ep_len = 8\n",
    "dir = \"data_parsed/step_6\"\n",
    "save_path = \"data_parsed/test_cases.json\"\n",
    "files = os.listdir(dir)\n",
    "\n",
    "for _ in range(num_levels):\n",
    "    rand_file_path = f\"{dir}/{random.choice(files)}\"\n",
    "    f = open(rand_file_path)\n",
    "    data = json.load(f)\n",
    "    state = data[\"init_state\"]\n",
    "    \n",
    "    for _ in range(ep_len):\n",
    "\n",
    "        rand_action = random.choice(dummy_model.suggest_actions(state))\n",
    "        action_type = rand_action.split(\" \")[0]\n",
    "        next_state = env.state_transition(set(state), rand_action)\n",
    "\n",
    "        trans = {\n",
    "            \"state\" : list(state),\n",
    "            \"action\" : rand_action,\n",
    "            \"next_state\" : list(next_state)\n",
    "        }\n",
    "\n",
    "        transitions[action_type].append(trans)\n",
    "        state = next_state\n",
    "\n",
    "for key, value in transitions.items():\n",
    "    print(key, len(value))\n",
    "\n",
    "tc_per_action_type = 100\n",
    "\n",
    "for key in transitions: \n",
    "    transitions[key] = transitions[key][:tc_per_action_type]\n",
    "\n",
    "with open(save_path, \"w\") as json_file:\n",
    "    json.dump(transitions, json_file, indent=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unstack 170\n",
      "stack 115\n",
      "pick-up 130\n",
      "put-down 85\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlvr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
