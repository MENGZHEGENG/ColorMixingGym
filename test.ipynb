{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "libtiff.so.5: cannot open shared object file: No such file or directory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# import pandas as pd\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mPIL\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Image\n",
      "File \u001b[0;32m~/miniconda3/envs/nlvr/lib/python3.10/site-packages/PIL/Image.py:103\u001b[0m\n\u001b[1;32m     94\u001b[0m MAX_IMAGE_PIXELS \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[38;5;241m1024\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1024\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1024\u001b[39m \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m4\u001b[39m \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;66;03m# If the _imaging C module is not present, Pillow will not load.\u001b[39;00m\n\u001b[1;32m     99\u001b[0m     \u001b[38;5;66;03m# Note that other modules should not refer to _imaging directly;\u001b[39;00m\n\u001b[1;32m    100\u001b[0m     \u001b[38;5;66;03m# import Image and use the Image.core variable instead.\u001b[39;00m\n\u001b[1;32m    101\u001b[0m     \u001b[38;5;66;03m# Also note that Image.core is not a publicly documented interface,\u001b[39;00m\n\u001b[1;32m    102\u001b[0m     \u001b[38;5;66;03m# and should be considered private and subject to change.\u001b[39;00m\n\u001b[0;32m--> 103\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _imaging \u001b[38;5;28;01mas\u001b[39;00m core\n\u001b[1;32m    105\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m __version__ \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(core, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPILLOW_VERSION\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    106\u001b[0m         msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    107\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe _imaging extension was built for another version of Pillow or PIL:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    108\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCore version: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mgetattr\u001b[39m(core,\u001b[38;5;250m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPILLOW_VERSION\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    109\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPillow version: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m__version__\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    110\u001b[0m         )\n",
      "\u001b[0;31mImportError\u001b[0m: libtiff.so.5: cannot open shared object file: No such file or directory"
     ]
    }
   ],
   "source": [
    "# import pandas as pd\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig =  go.Figure()\n",
    "for file in os.listdir(dir_path):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.1\n",
       "1    0.1\n",
       "2    0.1\n",
       "Name: amount_score, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# file_path = os.path.join(dir_path, file)\n",
    "df = pd.read_csv('results/level1/beige.csv')\n",
    "color_scores = df['color_score']\n",
    "amount_scores = df['amount_score']\n",
    "\n",
    "# weighted_scores = \n",
    "# line_trace = go.Scatter(x=df['iteration'],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('results/l1-no-refine.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"--- REASONING START ---\\nThe target color is a very light shade of orange, which means I need to mix red and green to get orange and then add a significant amount of white to lighten it. Since I don't have white, I can simulate it by using all three primary colors (red, green, blue) in such a way that the mixture is much lighter than the primary colors themselves. The RGB values of the target color are very high and close to each other, with red being the highest, followed by green, and then blue.\\n\\nTo achieve the target amount of 130ml, I need to plan the proportions of each color carefully. Since the red value is the highest, I will start by adding a large amount of red. The green value is slightly lower, so I will add a little less green than red. The blue value is the lowest, so I will add even less blue.\\n\\nI will use beaker 3 as my mixing beaker. I will start by adding red and green to get an orange base. Then, I will add a small amount of blue to lighten the color. I will adjust the amounts to get as close as possible to the target color while also reaching the target volume of 130ml.\\n\\nLet's assume I start with 60ml of red and 50ml of green to create a base orange color. This gives me 110ml of paint. I then need to add 20ml of blue to reach the target volume. This will lighten the color, but it may not be enough to reach the desired lightness. I may need to adjust the amounts after mixing to get closer to the target color.\\n\\nHere's an initial plan:\\n- 60ml of red (255, 0, 0)\\n- 50ml of green (0, 255, 0)\\n- 20ml of blue (0, 0, 255)\\n\\nThis will give me a starting point to evaluate the color and make further adjustments if necessary.\\n--- REASONING END ---\\n\\n--- PLAN START ---\\nPOUR(0, 3, 60) # pour 60 ml of red paint into beaker 3\\nPOUR(1, 3, 50) # pour 50 ml of green paint into beaker 3\\nPOUR(2, 3, 20) # pour 20 ml of blue paint into beaker 3\\nDONE(3) # the mixture in beaker 3 should be close to the target color and amount\\n--- PLAN END ---\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pd.set_option('display.max_colwidth', -1)\n",
    "df = pd.read_csv('results/l1-no-refine.csv')\n",
    "list(df.loc[df['name'] == 'beige.txt', 'llm_response'])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=['name', 'color_score', 'amount_score', 'llm_response'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[len(df)] = ('bruh', 1, 0.9, 'there was once a man')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('results/test', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from openai import OpenAI\n",
    "# client = OpenAI()\n",
    "from langchain.agents import load_tools, initialize_agent, AgentType\n",
    "from langchain.llms import OpenAI\n",
    "client = OpenAI()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/edwin/miniconda3/envs/nlvr/lib/python3.10/site-packages/langchain_core/utils/utils.py:159: UserWarning: WARNING! system_prompt is not default parameter.\n",
      "                system_prompt was transferred to model_kwargs.\n",
      "                Please confirm that system_prompt is what you intended.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "llm = OpenAI(\n",
    "    temperature=0.5,\n",
    "    model_name=\"gpt-3.5-turbo-instruct\"\n",
    ") \n",
    "                             \n",
    "tools = load_tools(['llm-math'], llm=llm)\n",
    "\n",
    "agent = initialize_agent(\n",
    "    llm=llm,\n",
    "    tools=tools,\n",
    "    agent=AgentType.CHAT_ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    verbose=True\n",
    ")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='Answer the following questions as best you can. You have access to the following tools:\\n\\nCalculator: Useful for when you need to answer questions about math.\\n\\nThe way you use the tools is by specifying a json blob.\\nSpecifically, this json should have a `action` key (with the name of the tool to use) and a `action_input` key (with the input to the tool going here).\\n\\nThe only values that should be in the \"action\" field are: Calculator\\n\\nThe $JSON_BLOB should only contain a SINGLE action, do NOT return a list of multiple actions. Here is an example of a valid $JSON_BLOB:\\n\\n```\\n{{\\n  \"action\": $TOOL_NAME,\\n  \"action_input\": $INPUT\\n}}\\n```\\n\\nALWAYS use the following format:\\n\\nQuestion: the input question you must answer\\nThought: you should always think about what to do\\nAction:\\n```\\n$JSON_BLOB\\n```\\nObservation: the result of the action\\n... (this Thought/Action/Observation can repeat N times)\\nThought: I now know the final answer\\nFinal Answer: the final answer to the original input question\\n\\nBegin! Reminder to always use the exact characters `Final Answer` when responding.')), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['agent_scratchpad', 'input'], template='{input}\\n\\n{agent_scratchpad}'))]\n"
     ]
    }
   ],
   "source": [
    "print(agent.agent.llm_chain.prompt.messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt=\"\"\"\n",
    "You are an agent in a \"color-mixing environment\". The environment consists \n",
    "    of several beakers, each containing a paint of a certain color and amount. \n",
    "    Your objective is to mix colors in beakers such that one beaker matches \n",
    "    a target beaker as close as possible (in both color and amount).\n",
    "\n",
    "    At each timestep, you will be given a textual representation of environment\n",
    "    which tells you the RGB value and amount of paints in each beaker as well\n",
    "    as the target beaker you are trying to achieve.\n",
    "    \n",
    "    Given this description of the envrionment, your task is to generate an \n",
    "    action in a specific JSON format. Each action is a JSON object that \n",
    "    represents a move in the envivronment. The action should consist of the \n",
    "    following elements:\n",
    "\n",
    "    - \"from_beaker\": An integer representing the index of the beaker from which the paint is poured.\n",
    "    - \"to_beaker\": An integer representing the index of the beaker to which the paint is poured.\n",
    "    - \"transfer_amount\": An integer (0 to 100) indicating how much paint (in ml) is transferred from the 'from_beaker' to the 'to_beaker'.\n",
    "    - \"is_done\": A boolean value (true or false). Set to true if this is the final action and you want to compare the current state with the target. Set to false otherwise.\n",
    "    - \"compare_beaker\": An integer representing the index of the beaker to compare with the target when 'is_done' is true. This field is only relevant if 'is_done' is true.\n",
    "\n",
    "    Your actions in the environment should work towards producing a beaker\n",
    "    which is as close as possible to the target beaker (in both color and \n",
    "    amount) in as few steps as possible.\n",
    "\n",
    "    Note that the environment uses a subtractive color mixing model. You should \n",
    "    leverage this fact to predict the result of mixing two colors for the \n",
    "    purposes of planning. For reference, this is the function used mix colors:\n",
    "\n",
    "    class SubtractiveModel:\n",
    "    @staticmethod\n",
    "    def _rgb_to_cmy(rgb: Tuple[int, int, int]) -> Tuple[int, int, int]:\n",
    "        return tuple(255 - value for value in rgb)\n",
    "\n",
    "    @staticmethod\n",
    "    def _cmy_to_rgb(cmy: Tuple[int, int, int]) -> Tuple[int, int, int]:\n",
    "        return tuple(255 - value for value in cmy)\n",
    "\n",
    "    @staticmethod\n",
    "    def mix_colors(paint1: 'Paint', paint2: 'Paint') -> Tuple[int, int, int]:\n",
    "        cmy1 = SubtractiveModel._rgb_to_cmy(paint1.color)\n",
    "        cmy2 = SubtractiveModel._rgb_to_cmy(paint2.color)\n",
    "        total_amount = paint1.amount + paint2.amount\n",
    "        if paint1.amount == 0:\n",
    "            return paint2.color\n",
    "        if paint2.amount == 0:\n",
    "            return paint1.color\n",
    "\n",
    "        mixed_cmy = tuple(int((cmy1[i] * paint1.amount + cmy2[i] * paint2.amount) / total_amount) for i in range(3))\n",
    "        return SubtractiveModel._cmy_to_rgb(mixed_cmy)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = []\n",
    "messages.append({\"role\": \"system\", \"content\": system_prompt})\n",
    "obs = \"\"\"Given the following beakers: \n",
    "Beaker 0: RGB(252, 251, 0), 107ml\n",
    "Beaker 1: RGB(0, 0, 0), 0ml\n",
    "Beaker 2: RGB(255, 0, 255), 80ml\n",
    "Beaker 3: RGB(200, 108, 52), 97ml\n",
    "Beaker 4: RGB(5, 255, 255), 101ml\n",
    "Target beaker: RGB(44, 220, 226), 63ml\n",
    "Please output your action given this state.\"\"\"\n",
    "messages.append({\"role\": \"user\", \"content\": obs})\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo-1106\",  \n",
    "    response_format={\"type\" : \"json_object\"},\n",
    "    messages=messages\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\\n  \"from_beaker\": 0,\\n  \"to_beaker\": 1,\\n  \"transfer_amount\": 63,\\n  \"is_done\": true,\\n  \"compare_beaker\": 1\\n}'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 1, 63, True, 1)\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "# Parse the JSON string\n",
    "action_json = response.choices[0].message.content\n",
    "action_data = json.loads(action_json)\n",
    "\n",
    "# Extract action components\n",
    "from_beaker = action_data.get(\"from_beaker\", 0)\n",
    "to_beaker = action_data.get(\"to_beaker\", 0)\n",
    "transfer_amount = action_data.get(\"transfer_amount\", 0)\n",
    "is_done = action_data.get(\"is_done\", False)\n",
    "compare_beaker = action_data.get(\"compare_beaker\", 0) if is_done else 0\n",
    "\n",
    "# Ensure the action components are within the bounds of the action space\n",
    "# from_beaker = min(max(from_beaker, 0), action_space.nvec[0] - 1)\n",
    "# to_beaker = min(max(to_beaker, 0), action_space.nvec[1] - 1)\n",
    "# transfer_amount = min(max(transfer_amount, 0), action_space.nvec[2] - 1)\n",
    "# is_done = 1 if is_done else 0\n",
    "# compare_beaker = min(max(compare_beaker, 0), action_space.nvec[4] - 1)\n",
    "\n",
    "# Construct the action tuple\n",
    "action = (from_beaker, to_beaker, transfer_amount, is_done, compare_beaker)\n",
    "print(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlvr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
